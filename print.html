<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Kubernetes Cluster API Provider for Oracle Cloud Infrastructure</title>
        <meta name="robots" content="noindex" />
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="./src/css/mdbook-admonish.css">
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="introduction.html">Introduction</a></li><li class="chapter-item expanded affix "><a href="prerequisites.html">Prerequisites</a></li><li class="chapter-item expanded "><a href="gs/gs.html"><strong aria-hidden="true">1.</strong> Getting Started</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="gs/overview.html"><strong aria-hidden="true">1.1.</strong> Overview</a></li><li class="chapter-item expanded "><a href="gs/custom-machine-images.html"><strong aria-hidden="true">1.2.</strong> Prepare custom OCI images</a></li><li class="chapter-item expanded "><a href="gs/iam.html"><strong aria-hidden="true">1.3.</strong> Configure users and policies</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="gs/iam/iam-oke.html"><strong aria-hidden="true">1.3.1.</strong> Configure policies for an OKE cluster</a></li><li class="chapter-item expanded "><a href="gs/iam/iam-self-provisioned.html"><strong aria-hidden="true">1.3.2.</strong> Configure policies for a self-provisioned cluster</a></li><li class="chapter-item expanded "><a href="gs/iam/iam-ocid.html"><strong aria-hidden="true">1.3.3.</strong> User configuration and OCIDs</a></li></ol></li><li class="chapter-item expanded "><a href="gs/provision-mgmt-cluster.html"><strong aria-hidden="true">1.4.</strong> Provision a management cluster</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="gs/mgmt/mgmt-kind.html"><strong aria-hidden="true">1.4.1.</strong> Provision a management cluster with kind</a></li><li class="chapter-item expanded "><a href="gs/mgmt/mgmt-oke.html"><strong aria-hidden="true">1.4.2.</strong> Provision a management cluster with OKE</a></li></ol></li><li class="chapter-item expanded "><a href="gs/install-cluster-api.html"><strong aria-hidden="true">1.5.</strong> Install Cluster API for Oracle Cloud Infrastructure</a></li><li class="chapter-item expanded "><a href="gs/create-workload-cluster.html"><strong aria-hidden="true">1.6.</strong> Create Workload Cluster</a></li><li class="chapter-item expanded "><a href="gs/create-workload-templates.html"><strong aria-hidden="true">1.7.</strong> Create Workload Templates</a></li><li class="chapter-item expanded "><a href="gs/externally-managed-infrastructure.html"><strong aria-hidden="true">1.8.</strong> Using externally managed infrastructure</a></li><li class="chapter-item expanded "><a href="gs/install-oci-ccm.html"><strong aria-hidden="true">1.9.</strong> Install Oracle Cloud Infrastructure Cloud Controller Manager</a></li><li class="chapter-item expanded "><a href="gs/install-csi.html"><strong aria-hidden="true">1.10.</strong> Install Container Storage Interface (CSI)</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="gs/pvc-bv.html"><strong aria-hidden="true">1.10.1.</strong> Provision a PVC on the Block Volume Service</a></li><li class="chapter-item expanded "><a href="gs/pvc-fss.html"><strong aria-hidden="true">1.10.2.</strong> Provision a PVC on the File Storage Service</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="networking/networking.html"><strong aria-hidden="true">2.</strong> Networking Guide</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="networking/infrastructure.html"><strong aria-hidden="true">2.1.</strong> Default Network Infrastructure</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="networking/calico.html"><strong aria-hidden="true">2.1.1.</strong> Using Calico</a></li><li class="chapter-item expanded "><a href="networking/antrea.html"><strong aria-hidden="true">2.1.2.</strong> Using Antrea</a></li></ol></li><li class="chapter-item expanded "><a href="networking/custom-networking.html"><strong aria-hidden="true">2.2.</strong> Custom Networking</a></li></ol></li><li class="chapter-item expanded "><a href="reference/reference.html"><strong aria-hidden="true">3.</strong> Reference</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="reference/glossary.html"><strong aria-hidden="true">3.1.</strong> Glossary</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Kubernetes Cluster API Provider for Oracle Cloud Infrastructure</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/oracle/cluster-api-provider-oci" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="kubernetes-cluster-api-provider-for-oracle-cloud-infrastructure"><a class="header" href="#kubernetes-cluster-api-provider-for-oracle-cloud-infrastructure">Kubernetes Cluster API Provider for Oracle Cloud Infrastructure</a></h1>
<p><a href="https://goreportcard.com/report/github.com/oracle/cluster-api-provider-oci"><img src="https://goreportcard.com/badge/github.com/oracle/cluster-api-provider-oci" alt="Go Report Card" /></a></p>
<!-- markdownlint-disable MD033 -->
<img src="https://github.com/kubernetes/kubernetes/raw/master/logo/logo.png"  width="100">
<hr />
<p>Kubernetes-native declarative infrastructure for Oracle Cloud Infrastructure (OCI).</p>
<h2 id="what-is-the-cluster-api-provider-for-oci"><a class="header" href="#what-is-the-cluster-api-provider-for-oci">What is the Cluster API Provider for OCI</a></h2>
<p>The <a href="https://github.com/oracle/cluster-api-provider-oci">Cluster API Provider for OCI (CAPOCI)</a> brings declarative, Kubernetes-style APIs to cluster 
creation, configuration and management.</p>
<p>The API itself is shared across multiple cloud providers allowing for true hybrid deployments of Kubernetes.</p>
<h2 id="features"><a class="header" href="#features">Features</a></h2>
<ul>
<li>Manages the bootstrapping of VCNs, gateways, subnets, network security groups and instances</li>
<li>Deploy either Oracle Linux or Ubuntu based instances using custom images built with the <a href="https://image-builder.sigs.k8s.io/capi/providers/oci.html">Image Builder</a> tool</li>
<li>Deploys Kubernetes control plane into private subnets front-ended by a public load balancer</li>
<li>Provides secure and sensible defaults</li>
</ul>
<h2 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h2>
<ul>
<li><a href="./prerequisites.html">Prerequisites</a>: Set up your OCI tenancy before using CAPOCI.</li>
<li><a href="./gs/overview.html">Deployment process</a>: Choosing your deployment path</li>
<li><a href="./networking/networking.html">Networking</a>: Networking guide</li>
<li>Installation:
<ul>
<li><a href="./gs/install-cluster-api.html">Install Cluster API for OCI</a></li>
<li><a href="./gs/create-workload-cluster.html">Create Workload Cluster</a></li>
</ul>
</li>
</ul>
<h2 id="support-policy"><a class="header" href="#support-policy">Support Policy</a></h2>
<div class="admonition info">
<div class="admonition-title">
<p>Info</p>
</div>
<div>
<p>As the versioning for this project is tied to the versioning of Cluster API, future modifications to this
policy may be made to more closely align with other providers in the Cluster API ecosystem.</p>
</div>
</div>
<h3 id="cluster-api-versions"><a class="header" href="#cluster-api-versions">Cluster API Versions</a></h3>
<table><thead><tr><th></th><th>v1beta1 (v1.0)</th></tr></thead><tbody>
<tr><td>OCI Provider v1beta1 (v0.1)</td><td>✓</td></tr>
</tbody></table>
<h3 id="supported-kubernetes-versions"><a class="header" href="#supported-kubernetes-versions">Supported Kubernetes versions</a></h3>
<table><thead><tr><th></th><th>v1.20</th><th>v1.21</th></tr></thead><tbody>
<tr><td>OCI Provider v1beta1 (v0.1)</td><td>✓</td><td>✓</td></tr>
</tbody></table>
<div style="break-before: page; page-break-before: always;"></div><h1 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h1>
<h2 id="requirements"><a class="header" href="#requirements">Requirements</a></h2>
<ul>
<li>
<p>An active <a href="https://cloud.oracle.com">Oracle Cloud Infrastructure (OCI) tenancy</a></p>
</li>
<li>
<p>An active user account in the tenancy</p>
</li>
<li>
<p>A supported version of <a href="https://docs.oracle.com/en-us/iaas/Content/API/Concepts/cliconcepts.htm"><code>oci-cli</code></a></p>
</li>
<li>
<p>A supported version of <a href="https://kubernetes.io/docs/reference/kubectl/kubectl/"><code>kubectl</code></a></p>
</li>
<li>
<p>A <a href="https://github.com/oracle/cluster-api-provider-oci#support-policy">supported version</a> of <a href="https://cluster-api.sigs.k8s.io/clusterctl/overview.html"><code>clusterctl</code></a></p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-started-1"><a class="header" href="#getting-started-1">Getting started</a></h1>
<p>This section contains information about enabling and configuring various Oracle Cloud Infrastructure (OCI) resources using the Kubernetes Cluster API Provider for OCI.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-started-with-kubernetes-cluster-api-provider-for-oracle-cloud-infrastructure"><a class="header" href="#getting-started-with-kubernetes-cluster-api-provider-for-oracle-cloud-infrastructure">Getting started with Kubernetes Cluster API Provider for Oracle Cloud Infrastructure</a></h1>
<p>Before deploying the Cluster API Provider for Oracle Cloud Infrastructure (CAPOCI), you must first configure the 
required Identity and Access Management (IAM) policies:</p>
<p><img src="gs/../images/iam.svg" alt="CAPOCI Installation Process" /></p>
<p>The following deployment options are available:</p>
<ul>
<li><a href="gs/overview.html#getting-started-with-kubernetes-cluster-api-provider-for-oracle-cloud-infracture">Getting started with Kubernetes Cluster API Provider for Oracle Cloud Infrastructure</a>
<ul>
<li><a href="gs/overview.html#setting-up-a-non-production-management-cluster">Setting up a non-production management cluster</a></li>
<li><a href="gs/overview.html#setting-up-a-management-cluster-using-an-initial-bootstrap-cluster">Setting up a management cluster using an initial bootstrap cluster</a></li>
<li><a href="gs/overview.html#setting-up-a-management-cluster-using-oke">Setting up a management cluster using OKE</a></li>
<li><a href="gs/overview.html#setting-up-a-management-cluster-using-a-3rd-party-kubernetes-cluster">Setting up a management cluster using a 3rd party Kubernetes cluster</a></li>
</ul>
</li>
</ul>
<p>The following workflow diagrams provide a high-level overview of each deployment method described above:</p>
<h2 id="setting-up-a-non-production-management-cluster"><a class="header" href="#setting-up-a-non-production-management-cluster">Setting up a non-production management cluster</a></h2>
<p><img src="gs/../images/nonprod.svg" alt="CAPOCI Installation Process" /></p>
<h2 id="setting-up-a-management-cluster-using-an-initial-bootstrap-cluster"><a class="header" href="#setting-up-a-management-cluster-using-an-initial-bootstrap-cluster">Setting up a management cluster using an initial bootstrap cluster</a></h2>
<p><img src="gs/../images/bootstrap.svg" alt="CAPOCI Installation Process" /></p>
<h2 id="setting-up-a-management-cluster-using-oke"><a class="header" href="#setting-up-a-management-cluster-using-oke">Setting up a management cluster using OKE</a></h2>
<p><img src="gs/../images/oke.svg" alt="CAPOCI Installation Process" /></p>
<h2 id="setting-up-a-management-cluster-using-a-3rd-party-kubernetes-cluster"><a class="header" href="#setting-up-a-management-cluster-using-a-3rd-party-kubernetes-cluster">Setting up a management cluster using a 3rd party Kubernetes cluster</a></h2>
<p><img src="gs/../images/3rdparty.svg" alt="CAPOCI Installation Process" /></p>
<p>Complete the following steps in order to install and use CAPOCI:</p>
<ol>
<li>Choose your management cluster. You can use <a href="https://kind.sigs.k8s.io/">kind</a>, <a href="https://docs.oracle.com/en-us/iaas/Content/ContEng/home.htm">OKE</a> or any other compliant Kubernetes clusters.</li>
<li><a href="gs/./custom-machine-images.html">Prepare custom machine images</a></li>
<li><a href="gs/./iam.html">Configure users and policies for the management cluster if required</a></li>
<li><a href="gs/./provision-mgmt-cluster.html">Provision a management cluster</a>. You can use <a href="https://kind.sigs.k8s.io/">kind</a>, <a href="https://docs.oracle.com/en-us/iaas/Content/ContEng/home.htm">OKE</a> or any other compliant Kubernetes clusters.</li>
<li>Install the necessary tools:
<ul>
<li><a href="https://docs.oracle.com/en-us/iaas/Content/API/Concepts/cliconcepts.htm">OCI CLI</a></li>
<li><a href="https://cluster-api.sigs.k8s.io/user/quick-start.html#install-clusterctl"><code>clusterctl</code></a></li>
<li><a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/"><code>kubectl</code></a></li>
</ul>
</li>
<li><a href="gs/iam/iam-self-provisioned.html">Configure IAM for the workload cluster</a>.</li>
<li><a href="gs/./install-cluster-api.html">Install Kubernetes Cluster API</a> for Oracle Cloud Infrastructure (CAPOCI) in the <em><strong>management cluster</strong></em>.</li>
<li><a href="gs/./create-workload-cluster.html">Create a workload cluster</a>.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configure-custom-machine-images"><a class="header" href="#configure-custom-machine-images">Configure Custom Machine Images</a></h1>
<p>An image is a template of a virtual hard drive. It determines the operating system and other software for a compute instance. In order to use CAPOCI, you must prepare one or more custom images which have all the necessary Kubernetes components pre-installed. The custom image(s) will then be used to instantiate the Kubernetes nodes.</p>
<h2 id="building-a-custom-image"><a class="header" href="#building-a-custom-image">Building a custom image</a></h2>
<p>To create your own custom image in your Oracle Cloud Infrastructure (OCI) tenancy, navigate to <a href="https://image-builder.sigs.k8s.io/capi/providers/oci.html">The Image Builder Book</a> and follow the instructions for OCI.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configure-user-and-policies"><a class="header" href="#configure-user-and-policies">Configure user and policies</a></h1>
<ul>
<li><a href="gs/iam/iam-oke.html">Configure policies for an OKE cluster</a></li>
<li><a href="gs/iam/iam-self-provisioned.html">Configure policies for a self-provisioned cluster</a></li>
<li><a href="gs/iam/iam-ocid.html">User configuration and OCIDs</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configure-oci-policies-for-an-oracle-container-engine-for-kubernetes-cluster"><a class="header" href="#configure-oci-policies-for-an-oracle-container-engine-for-kubernetes-cluster">Configure OCI policies for an Oracle Container Engine for Kubernetes cluster</a></h1>
<p>These steps are applicable if you intend to run your management cluster using <a href="https://docs.oracle.com/en-us/iaas/Content/ContEng/home.htm">Oracle Container Engine for Kubernetes</a> (OKE). They need to be created by a user with admin privileges and are required so you can provision your OKE cluster successfully. If you plan to run your management cluster in <a href="https://kind.sigs.k8s.io/">kind</a> or a non-OKE cluster, you can skip this step.</p>
<ol>
<li><a href="https://docs.oracle.com/en-us/iaas/Content/Identity/Tasks/managingusers.htm">Create a user in OCI</a> e.g. <code>iaas_oke_usr</code></li>
<li><a href="https://docs.oracle.com/en-us/iaas/Content/Identity/Tasks/managinggroups.htm">Create a group in OCI</a> e.g. <code>iaas_oke_grp</code> and add the user <code>iaas_oke_usr</code> to this group</li>
<li>Create a policy in OCI and add the following policies:
<ul>
<li><code>Allow group iaas_oke_grp to manage dynamic groups</code></li>
<li><code>Allow group iaas_oke_grp to manage virtual-network-family in &lt;compartment&gt;</code></li>
<li><code>Allow group iaas_oke_grp to manage cluster family in &lt;compartment&gt;</code></li>
<li><code>Allow group iaas_oke_grp to manage instance-family in &lt;compartment&gt;</code></li>
</ul>
</li>
</ol>
<p>where <code>&lt;compartment&gt;</code> is the name of the OCI compartment of the management cluster. Refer to the <a href="https://docs.oracle.com/en-us/iaas/Content/Identity/Tasks/managingcompartments.htm">OCI documentation</a> if you have not created a compartment yet.</p>
<div class="admonition warning">
<div class="admonition-title">
<p>Warning</p>
</div>
<div>
<p>You should not create your management cluster in the root compartment.</p>
</div>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configure-policies-for-a-self-provisioned-cluster"><a class="header" href="#configure-policies-for-a-self-provisioned-cluster">Configure policies for a self-provisioned cluster</a></h1>
<p>Although some policies required for Oracle Container Engine for Kubernetes (OKE) and self-provisioned clusters may overlap, we recommend you create another user and group for the principal that will be provisioning the self-provisioned clusters.</p>
<ol>
<li><a href="https://docs.oracle.com/en-us/iaas/Content/Identity/Tasks/managingusers.htm">Create a user in OCI</a> e.g. <code>cluster_api_usr</code></li>
<li><a href="https://docs.oracle.com/en-us/iaas/Content/Identity/Tasks/managinggroups.htm">Create a group in OCI</a> e.g. <code>cluster_api_grp</code> and add the user <code>cluster_api_usr</code> to this group</li>
<li>Create a policy in OCI and add the following policies:
<ul>
<li><code>Allow group cluster_api_grp to manage virtual-network-family in &lt;compartment&gt;</code></li>
<li><code>Allow group cluster_api_grp to manage load-balancers in &lt;compartment&gt;</code></li>
<li><code>Allow group cluster_api_grp to manage instance-family in &lt;compartment&gt;</code></li>
</ul>
</li>
</ol>
<p>where <code>&lt;compartment&gt;</code> is the name of the OCI compartment of the workload cluster. Your workload compartment may be different from the management compartment. Refer to the <a href="https://docs.oracle.com/en-us/iaas/Content/Identity/Tasks/managingcompartments.htm">OCI documentation</a> if you have not created a compartment yet.</p>
<div class="admonition info">
<div class="admonition-title">
<p>Info</p>
</div>
<div>
<p>If you are an administrator and you are experimenting with CAPOCI, you can skip creating the policies.</p>
</div>
</div>
<ol>
<li>Repeat the procedure as for the <code>iaas_oke_usr</code> above to obtain the IAM details.</li>
</ol>
<div class="admonition warning">
<div class="admonition-title">
<p>Warning</p>
</div>
<div>
<p>You should not create your workload cluster in the root compartment.</p>
</div>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="user-configuration-and-ocids"><a class="header" href="#user-configuration-and-ocids">User configuration and OCIDs</a></h1>
<ol>
<li>
<p>Login as the <code>iaas_oke_usr</code> in the OCI Console to configure your OCI key. You can either use the OCI console or openssl to <a href="https://docs.oracle.com/en-us/iaas/Content/API/Concepts/apisigningkey.htm#two">generate an API key</a>.</p>
</li>
<li>
<p>Obtain the following details which you will need in order to create your management cluster with OKE:</p>
<ul>
<li><code>&lt;compartment&gt;</code> OCID
<ul>
<li>Navigate to Identity &gt; Compartments</li>
<li>Click on your compartment</li>
<li>Locate OCID on the page and click on <strong>Copy</strong></li>
</ul>
</li>
<li><a href="https://docs.oracle.com/en-us/iaas/Content/API/Concepts/apisigningkey.htm#five">Tenancy OCID</a></li>
<li><a href="https://docs.oracle.com/en-us/iaas/Content/API/Concepts/apisigningkey.htm#five">User OCID</a></li>
<li><a href="https://docs.oracle.com/en-us/iaas/Content/API/Concepts/apisigningkey.htm#four">API key fingerprint</a></li>
</ul>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="provision-a-management-cluster"><a class="header" href="#provision-a-management-cluster">Provision a management cluster</a></h1>
<p>Cluster API Provider for Oracle Cloud Infrastructure is installed into an existing Kubernetes cluster, called the <a href="https://cluster-api.sigs.k8s.io/user/concepts.html#management-cluster">management cluster</a>.</p>
<p>You may use <a href="https://kind.sigs.k8s.io/">kind</a> for experimental purposes or for creating a <a href="https://cluster-api.sigs.k8s.io/user/quick-start.html#install-andor-configure-a-kubernetes-cluster">local bootstrap cluster</a> which you will then use to provision a target management cluster.</p>
<ul>
<li><a href="gs/./mgmt/mgmt-kind.html">Create a local management or bootstrap cluster with kind</a></li>
</ul>
<p>For a more durable environment, we recommend using a managed Kubernetes service such as <a href="https://docs.oracle.com/en-us/iaas/Content/ContEng/home.htm">Oracle Container Engine for Kubernetes</a> (OKE).</p>
<ul>
<li><a href="gs/./mgmt/mgmt-oke.html">Create a management cluster with OKE</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="provision-a-management-cluster-using-kind"><a class="header" href="#provision-a-management-cluster-using-kind">Provision a management cluster using <a href="https://kind.sigs.k8s.io/">kind</a></a></h1>
<ol>
<li>
<p>Create the cluster</p>
<pre><code class="language-shell">  kind create cluster
</code></pre>
</li>
<li>
<p>Configure access</p>
<pre><code class="language-shell">  kubectl config set-context kind-kind
</code></pre>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="provision-a-management-cluster-with-oracle-container-engine-for-kubernetes"><a class="header" href="#provision-a-management-cluster-with-oracle-container-engine-for-kubernetes">Provision a management cluster with Oracle Container Engine for Kubernetes</a></h1>
<p>For this release, if you use <a href="https://docs.oracle.com/en-us/iaas/Content/ContEng/home.htm">Oracle Container Engine for Kubernetes</a> (OKE) for your management cluster, you will be provisioning a public Kubernetes cluster i.e. its API server must be accessible to <code>kubectl</code>. You can use either use the OCI console to do the provisioning or the <a href="https://github.com/oracle-terraform-modules/terraform-oci-oke">terraform-oci-oke</a> project.</p>
<ol>
<li>
<p>Login to the OCI Console as the <code>iaas_oke_usr</code></p>
</li>
<li>
<p>Search for OKE and select it:</p>
<p><img src="gs/mgmt/../../images/oke_1.png" alt="OKE" /></p>
</li>
<li>
<p>Select the right compartment where you will be creating the OKE Cluster:</p>
<p><img src="gs/mgmt/../../images/oke_2.png" alt="OKE" /></p>
</li>
<li>
<p>Click <strong>Create Cluster</strong>, select <strong>Quick Create</strong> and click <strong>Launch Workflow</strong>:</p>
<p><img src="gs/mgmt/../../images/oke_3.png" alt="OKE" /></p>
</li>
<li>
<p>Name your cluster and ensure you select <strong>Public Endpoint</strong> and choose <strong>Private Workers</strong>:</p>
<p><img src="gs/mgmt/../../images/oke_4.png" alt="OKE" /></p>
</li>
<li>
<p>Click <strong>Next</strong> and <strong>Create Cluster</strong>.</p>
</li>
<li>
<p>When the cluster is ready, set up access to the OKE cluster. You can either use</p>
<ul>
<li><a href="https://docs.oracle.com/en-us/iaas/Content/ContEng/Tasks/contengdownloadkubeconfigfile.htm#cloudshelldownload">OCI Cloud Shell</a></li>
<li>or <a href="https://docs.oracle.com/en-us/iaas/Content/ContEng/Tasks/contengdownloadkubeconfigfile.htm#localdownload">your local terminal</a>.</li>
</ul>
</li>
</ol>
<div class="admonition warning">
<div class="admonition-title">
<p>Warning</p>
</div>
<div>
<p>If you are working with an existing Kubernetes cluster and have an existing <code>kubeconfig</code> in your <code>$HOME/.kube/config</code> directory, running the command to set up local access will add a new cluster context to your existing <code>kubeconfig</code>.</p>
</div>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="install-cluster-api-provider-for-oracle-cloud-infrastructure"><a class="header" href="#install-cluster-api-provider-for-oracle-cloud-infrastructure">Install Cluster API Provider for Oracle Cloud Infrastructure</a></h1>
<ol>
<li>
<p>If you are not using <a href="https://kind.sigs.k8s.io/">kind</a> for your management cluster, export the <code>KUBECONFIG</code> environment variable to point to the correct Kubeconfig file.</p>
<pre><code class="language-shell">export KUBECONFIG=/path/to/kubeconfig
</code></pre>
</li>
<li>
<p>Create a file <code>clusterctl.yaml</code> in <code>$HOME/.cluster-api/</code></p>
<pre><code class="language-shell">  touch &quot;$HOME&quot;/.cluster-api/clusterctl.yaml
</code></pre>
</li>
<li>
<p>Add the Oracle Cloud Infrastructure (OCI) Provider in <code>clusterctl.yaml</code>:</p>
<pre><code class="language-yaml">providers:
  - name: oci
    url: https://github.com/oracle/cluster-api-provider-oci/releases/v0.1.0/infrastructure-components.yaml
    type: InfrastructureProvider
</code></pre>
</li>
</ol>
<h2 id="configure-authentication"><a class="header" href="#configure-authentication">Configure authentication</a></h2>
<p>Before installing Cluster API Provider for OCI (CAPOCI), you must first set up your preferred authentication mechanism using specific environment variables:</p>
<pre><code class="language-bash">   export OCI_TENANCY_ID=&lt;tenancy-id&gt;
   export OCI_USER_ID=&lt;user-id&gt;
   export OCI_CREDENTIALS_FINGERPRINT=&lt;fingerprint&gt;
   export OCI_REGION=&lt;region&gt;
   # if Passphrase is present
   export OCI_CREDENTIALS_PASSPHRASE=&lt;passphrase&gt;
   export OCI_TENANCY_ID_B64=&quot;$(echo -n &quot;$OCI_TENANCY_ID&quot; | base64 | tr -d '\n')&quot;
   export OCI_CREDENTIALS_FINGERPRINT_B64=&quot;$(echo -n &quot;$OCI_CREDENTIALS_FINGERPRINT&quot; | base64 | tr -d '\n')&quot;
   export OCI_USER_ID_B64=&quot;$(echo -n &quot;$OCI_USER_ID&quot; | base64 | tr -d '\n')&quot;
   export OCI_REGION_B64=&quot;$(echo -n &quot;$OCI_REGION&quot; | base64 | tr -d '\n')&quot;
   export OCI_CREDENTIALS_KEY_B64=$(base64 &lt; &lt;path-to-api-private-key-file&gt; | tr -d '\n')
   # if Passphrase is present
   export OCI_CREDENTIALS_PASSPHRASE_B64=&quot;$(echo -n &quot;OCI_CREDENTIALS_PASSPHRASE&quot; | base64 | tr -d '\n')&quot;
</code></pre>
<h2 id="initialize-management-cluster"><a class="header" href="#initialize-management-cluster">Initialize management cluster</a></h2>
<p>Initialize management cluster and install CAPOCI</p>
<pre><code class="language-bash">   clusterctl init --infrastructure oci
</code></pre>
<h2 id="capoci-components"><a class="header" href="#capoci-components">CAPOCI Components</a></h2>
<p>When installing CAPOCI, the following components will be installed in the management cluster:</p>
<ol>
<li>A custom resource definition (<code>CRD</code>) for <code>OCICluster</code>, which is a Kubernetes custom resource that represents a workload cluster created in OCI by CAPOCI.</li>
<li>A custom resource definition (<code>CRD</code>) for <code>OCIMachine</code>, which is a Kubernetes custom resource that represents one node in the workload cluster created in OCI by CAPOCI.</li>
<li>Role-based access control resources for a Kubernetes <code>Deployment</code>, <code>ServiceAccount</code>, <code>Role</code>, <code>ClusterRole</code> and <code>ClusterRoleBinding</code></li>
<li>A Kubernetes <code>Secret</code> which will hold OCI credentials</li>
<li>A Kubernetes <code>Deployment</code> with the CAPOCI image - ghcr.io/oracle/cluster-api-oci-controller: <code>&lt;version&gt;</code></li>
</ol>
<p>Please inspect the <code>infrastructure-components.yaml</code> present in the release artifacts to know more.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="create-a-workload-cluster"><a class="header" href="#create-a-workload-cluster">Create a workload cluster</a></h1>
<h2 id="workload-cluster-templates"><a class="header" href="#workload-cluster-templates">Workload Cluster Templates</a></h2>
<p>The workload cluster templates can be downloaded from the <a href="https://github.com/oracle/cluster-api-provider-oci/releases/tag/v0.1.0">latest released artifacts</a>.</p>
<h2 id="workload-cluster-parameters"><a class="header" href="#workload-cluster-parameters">Workload Cluster Parameters</a></h2>
<p>The following Oracle Cloud Infrastructure (OCI) configuration parameters are available when creating a workload cluster on OCI:</p>
<table><thead><tr><th>Parameter</th><th>Default Value</th><th>Description</th></tr></thead><tbody>
<tr><td><code>OCI_COMPARTMENT_ID</code></td><td></td><td>The OCID of the compartment where the OCI resources are to be created</td></tr>
<tr><td><code>OCI_IMAGE_ID</code></td><td></td><td>The OCID of the Compute Image (Oracle Linux or Ubuntu) with which to create the Kubernetes nodes</td></tr>
<tr><td><code>OCI_SHAPE</code></td><td>VM.Standard.E4.Flex</td><td>The shape of the Kubernetes nodes</td></tr>
<tr><td><code>OCI_SHAPE_MEMORY_IN_GBS</code></td><td></td><td>The amount of memory to be allocated to the instances. If not provided it is automatically computed by compute API.</td></tr>
<tr><td><code>OCI_SHAPE_OCPUS</code></td><td>1</td><td>The number of OCPUs allocated to the instance</td></tr>
<tr><td><code>OCI_SSH_KEY</code></td><td></td><td>The public SSH key to be added to the Kubernetes nodes. It can be used to login to the node and troubleshoot failures.</td></tr>
<tr><td><code>OCI_PV_TRANSIT_ENCRYPTION</code></td><td>true</td><td><a href="https://docs.oracle.com/en-us/iaas/Content/File/Tasks/intransitencryption.htm">In-transit encryption</a> provides a way to secure your data between instances and mounted file systems using TLS v.1.2 (Transport Layer Security) encryption. Only <a href="https://docs.oracle.com/en-us/iaas/releasenotes/changes/60d602f5-abb3-4639-aa19-292a5744a808/">some bare metal instances</a> support In-transit encryption</td></tr>
</tbody></table>
<p>The following Cluster API parameters are also available:</p>
<table><thead><tr><th>Parameter</th><th>Default Value</th><th>Description</th></tr></thead><tbody>
<tr><td><code>CLUSTER_NAME</code></td><td></td><td>The name of the workload cluster to create</td></tr>
<tr><td><code>CONTROL_PLANE_MACHINE_COUNT</code></td><td>1</td><td>The number of control plane machines for the workload cluster.</td></tr>
<tr><td><code>KUBERNETES_VERSION</code></td><td></td><td>The Kubernetes version to use for the workload cluster. If unspecified, the value from OS environment variables or the .cluster-api/clusterctl.yaml config file will be used.</td></tr>
<tr><td><code>NAMESPACE</code></td><td></td><td>The namespace to use for the workload cluster. If unspecified, the current namespace will be used</td></tr>
<tr><td><code>POD_CIDR</code></td><td>1</td><td>The CIDR range for the Kubernetes POD network.</td></tr>
<tr><td><code>SERVICE_CIDR</code></td><td></td><td>The CIDR for the Kubernetes services network.</td></tr>
<tr><td><code>SERVICE_DOMAIN</code></td><td></td><td></td></tr>
<tr><td><code>WORKER_MACHINE_COUNT</code></td><td></td><td>The number of worker machines for the workload cluster.</td></tr>
</tbody></table>
<h2 id="using-an-ubuntu-custom-image-on-virtual-instances"><a class="header" href="#using-an-ubuntu-custom-image-on-virtual-instances">Using an Ubuntu custom image on virtual instances</a></h2>
<p>Run the command below to create a Kubernetes cluster with 1 control plane node and 1 worker node:</p>
<pre><code class="language-bash">OCI_COMPARTMENT_ID=&lt;compartment-id&gt; \
OCI_IMAGE_ID=&lt;ubuntu-custom-image-id&gt; \
OCI_SHAPE=VM.Standard.E4.Flex \
OCI_SHAPE_OCPUS=1 \
OCI_SHAPE_MEMORY_IN_GBS= \
OCI_SSH_KEY=&lt;ssh-key&gt;  \
CONTROL_PLANE_MACHINE_COUNT=1 \
KUBERNETES_VERSION=v1.20.10 \
NAMESPACE=default \
WORKER_MACHINE_COUNT=1 \
clusterctl generate cluster &lt;cluster-name&gt;\
--from cluster-template.yaml | kubectl apply -f -
</code></pre>
<h2 id="using-an-ubuntu-custom-image-on-bare-metal-instances"><a class="header" href="#using-an-ubuntu-custom-image-on-bare-metal-instances">Using an Ubuntu custom image on bare metal instances</a></h2>
<p>Note the addition of <code>OCI_PV_TRANSIT_ENCRYPTION=false</code> which is required for most BM shapes.</p>
<pre><code class="language-bash">OCI_COMPARTMENT_ID=&lt;compartment-id&gt; \
OCI_IMAGE_ID=&lt;ubuntu-custom-image-id&gt; \
OCI_SHAPE=BM.Standard2.52 \
OCI_SHAPE_OCPUS=52 \
OCI_SHAPE_MEMORY_IN_GBS= \
OCI_SSH_KEY=&lt;ssh-key&gt;  \
OCI_PV_TRANSIT_ENCRYPTION=false \
CONTROL_PLANE_MACHINE_COUNT=1 \
KUBERNETES_VERSION=v1.20.10 \
NAMESPACE=default \
WORKER_MACHINE_COUNT=1 \
clusterctl generate cluster &lt;cluster-name&gt;\
--from cluster-template.yaml| kubectl apply -f -
</code></pre>
<h2 id="using-an-oracle-linux-custom-image-on-virtual-instances"><a class="header" href="#using-an-oracle-linux-custom-image-on-virtual-instances">Using an Oracle Linux custom image on virtual instances</a></h2>
<pre><code class="language-bash">OCI_COMPARTMENT_ID=&lt;compartment-id&gt; \
OCI_IMAGE_ID=&lt;oracle-linux-custom-image-id&gt; \
OCI_SHAPE=VM.Standard.E4.Flex \
OCI_SHAPE_OCPUS=1 \
OCI_SHAPE_MEMORY_IN_GBS= \
OCI_SSH_KEY=&lt;ssh-key&gt;  \
CONTROL_PLANE_MACHINE_COUNT=1 \
KUBERNETES_VERSION=v1.20.10 \
NAMESPACE=default \
WORKER_MACHINE_COUNT=1 \
clusterctl generate cluster &lt;cluster-name&gt;\
--from cluster-template-oraclelinux.yaml | kubectl apply -f -
</code></pre>
<h3 id="access-workload-cluster-kubeconfig"><a class="header" href="#access-workload-cluster-kubeconfig">Access workload cluster Kubeconfig</a></h3>
<p>Execute the following command to list all the workload clusters present:</p>
<pre><code class="language-bash">kubectl get clusters -A
</code></pre>
<p>Execute the following command to access the kubeconfig of a workload cluster:</p>
<pre><code class="language-bash">clusterctl get kubeconfig &lt;cluster-name&gt; -n default &gt; &lt;cluster-name&gt;.kubeconfig
</code></pre>
<h3 id="install-a-cni-provider"><a class="header" href="#install-a-cni-provider">Install a CNI Provider</a></h3>
<p>After creating a workload cluster, a <a href="https://www.cni.dev/">CNI</a> provider must be installed in the workload cluster. Until you install a
a <a href="https://www.cni.dev/">CNI</a> provider, the cluster nodes will not go into the <code>Ready</code> state.</p>
<p>For example, you can install <a href="gs/../networking/calico.html">Calico</a> as follows:</p>
<pre><code class="language-bash">kubectl --kubeconfig=&lt;cluster-name&gt;.kubeconfig \
  apply -f https://docs.projectcalico.org/v3.21/manifests/calico.yaml
</code></pre>
<p>You can use your preferred CNI provider. Currently, the following providers have been tested and verified to work:</p>
<table><thead><tr><th>CNI</th><th>CNI Version</th><th>Kubernetes Version</th><th>CAPOCI Version</th></tr></thead><tbody>
<tr><td><a href="gs/../networking/calico.html">Calico</a></td><td>3.21</td><td>1.20.10</td><td>0.1</td></tr>
<tr><td><a href="gs/../networking/antrea.html">Antrea</a></td><td></td><td>1.20.10</td><td>0.1</td></tr>
</tbody></table>
<p>If you have tested an alternative CNI provider and verified it to work, please send us a PR to add it to the list.</p>
<p>If you have an issue with your alternative CNI provider, please raise an issue on GitHub.</p>
<h3 id="install-oci-cloud-controller-manager-and-csi-in-a-self-provisioned-cluster"><a class="header" href="#install-oci-cloud-controller-manager-and-csi-in-a-self-provisioned-cluster">Install OCI Cloud Controller Manager and CSI in a self-provisioned cluster</a></h3>
<p>By default, the <a href="https://github.com/oracle/oci-cloud-controller-manager">OCI Cloud Controller Manager (CCM)</a> is not installed into a workload cluster. To install the OCI CCM, run the following command:</p>
<!-- The above templates do not install the OCI CCM and CSI Driver in the workload cluster. The following command can be used
to install CCM and CSI by default in the workload clusters using ClusterResourceSet functionality provided by
Cluster API. -->
<pre><code class="language-bash">OCI_IMAGE_ID=&lt;ubuntu-custom-image-id&gt; \
OCI_COMPARTMENT_ID=&lt;compartment-id&gt; \
WORKER_MACHINE_COUNT=1 \
OCI_SHAPE=VM.Standard.E4.Flex \
OCI_SHAPE_OCPUS=1 \
OCI_SHAPE_MEMORY_IN_GBS= \
OCI_SSH_KEY=&lt;ssh-key&gt;  \
clusterctl generate cluster &lt;cluster-name&gt; --kubernetes-version v1.20.10 \
--target-namespace default \
--control-plane-machine-count=1 \
--from cluster-template-oci-addons.yaml | kubectl apply -f -
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="create-workload-templates-for-oracle-cloud-infrastructure"><a class="header" href="#create-workload-templates-for-oracle-cloud-infrastructure">Create Workload Templates for Oracle Cloud Infrastructure</a></h1>
<p>You can create workload clusters based on template files or you can also save the templates in <code>ConfigMaps</code> that you can then reuse.</p>
<h2 id="creating-cluster-templates-configmaps"><a class="header" href="#creating-cluster-templates-configmaps">Creating cluster templates ConfigMaps</a></h2>
<ol>
<li>Create a cluster template for Oracle Linux:</li>
</ol>
<pre><code class="language-shell">kubectl create cm oracletemplate --from-file=template=templates/cluster-template-oraclelinux.yaml
</code></pre>
<ol>
<li>Create a cluster template for Ubuntu:</li>
</ol>
<pre><code class="language-shell">kubectl create cm ubuntutemplate --from-file=template=templates/cluster-template.yaml
</code></pre>
<p>You can then reuse the <code>ConfigMap</code> to create your clusters. For example, to create a workload cluster using Oracle Linux, you can create it as follows:</p>
<pre><code class="language-shell">OCI_COMPARTMENT_ID=&lt;compartment-id&gt; \
OCI_IMAGE_ID=&lt;oracle-linux-custom-image-id&gt; \
OCI_SHAPE=VM.Standard.E4.Flex \
OCI_SHAPE_OCPUS=1 \
OCI_SHAPE_MEMORY_IN_GBS= \
OCI_SSH_KEY=&lt;ssh-key&gt;  \
CONTROL_PLANE_MACHINE_COUNT=1 \
KUBERNETES_VERSION=v1.20.10 \
NAMESPACE=default \
WORKER_MACHINE_COUNT=1 \
clusterctl generate cluster &lt;cluster-name&gt;\
--from-config-map oracletemplate | kubectl apply -f -
</code></pre>
<p>Likewise, to create a workload cluster using Ubuntu:</p>
<pre><code class="language-shell">OCI_COMPARTMENT_ID=&lt;compartment-id&gt; \
OCI_IMAGE_ID=&lt;ubuntu-custom-image-id&gt; \
OCI_SHAPE=VM.Standard.E4.Flex \
OCI_SHAPE_OCPUS=1 \
OCI_SHAPE_MEMORY_IN_GBS= \
OCI_SSH_KEY=&lt;ssh-key&gt;  \
CONTROL_PLANE_MACHINE_COUNT=1 \
KUBERNETES_VERSION=v1.20.10 \
NAMESPACE=default \
WORKER_MACHINE_COUNT=1 \
clusterctl generate cluster &lt;cluster-name&gt;\
--from-config-map ubuntutemplate | kubectl apply -f -
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="externally-managed-infrastructure"><a class="header" href="#externally-managed-infrastructure">Externally managed infrastructure</a></h1>
<p>By default, Cluster API will create resources on Oracle Cloud Infrastructure (OCI) when instantiating a new workload cluster. However, it is possible to have Cluster API re-use an existing OCI infrastructure instead of creating a new one. The existing infrastructure could include:</p>
<ol>
<li>Virtual cloud networks (VCNs)</li>
<li>Network load balancers used as Kubernetes API Endpoint</li>
</ol>
<p>CAPOCI supports <a href="https://github.com/kubernetes-sigs/cluster-api/blob/10d89ceca938e4d3d94a1d1c2b60515bcdf39829/docs/proposals/20210203-externally-managed-cluster-infrastructure.md">externally managed cluster infrastructure</a>.</p>
<p>If the <code>OCICluster</code> resource includes a <code>cluster.x-k8s.io/managed-by</code> annotation, then the <a href="https://cluster-api.sigs.k8s.io/developer/providers/cluster-infrastructure.html#normal-resource">controller will skip any reconciliation</a>.</p>
<p>This is useful for scenarios where a different persona is managing the cluster infrastructure out-of-band while still wanting to use CAPOCI for automated machine management.</p>
<h2 id="example-ocicluster-spec-with-external-infrastructure"><a class="header" href="#example-ocicluster-spec-with-external-infrastructure">Example <code>OCICluster</code> Spec with external infrastructure</a></h2>
<p>The following <code>OCICluster</code> Spec includes the mandatory fields to be specified for externally managed infrastructure to work properly.</p>
<pre><code class="language-yaml">apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: OCICluster
metadata:
  labels:
    cluster.x-k8s.io/cluster-name: &quot;${CLUSTER_NAME}&quot;
  annotations:
    cluster.x-k8s.io/managed-by: &quot;external&quot;
  name: &quot;${CLUSTER_NAME}&quot;
spec:
  compartmentId: &quot;${OCI_COMPARTMENT_ID}&quot;
  controlPlaneEndpoint:
    host: &lt;Control Plane Endpoint Address should go here&gt;
    port: 6443
  networkSpec:
    apiServerLoadBalancer:
      loadBalancerId: &lt;OCID of Control Plane Endpoint LoadBalancer&gt;
    vcn:
      id: &lt;OCID of VCN&gt;
      networkSecurityGroups:
        - id: &lt;OCID of Control Plane NSG&gt;
          name: &lt;Name of Control Plane NSG&gt;
          role: control-plane
        - id: &lt;OCID of Worker NSG&gt;
          name: &lt;Name of Worker NSG&gt;
          role: worker
      subnets:
        - id: &lt;OCID of Control Plane Subnet&gt;
          role: control-plane
        - id: &lt;OCID of Worker Subnet&gt;
          role: worker
</code></pre>
<h2 id="status"><a class="header" href="#status">Status</a></h2>
<p>As per the Cluster API Provider specification, the <code>OCICluster Status</code> Object has to be updated with <code>ready</code> status
as well as the failure domain mapping. This has to be done after the <code>OCICluster</code> object has been created in the management cluster.
The following cURL request illustrates this:</p>
<p>Get a list of <a href="gs/../reference/glossary.html#ad">Availability Domains</a> of the region:</p>
<pre><code class="language-bash">oci iam availability-domain list
</code></pre>
<div class="admonition info">
<div class="admonition-title">
<p>Info</p>
</div>
<div>
<p>Review the <a href="https://docs.oracle.com/en-us/iaas/Content/API/Concepts/cliconcepts.htm">OCI CLI documentation</a> for more information regarding this tool.</p>
</div>
</div>
<p>For 1-AD regions, use the following cURL command to update the status object:</p>
<pre><code class="language-bash">curl -o  -s -X PATCH -H &quot;Accept: application/json, */*&quot; \
-H &quot;Content-Type: application/merge-patch+json&quot; \
--cacert ca.crt \
--cert client.crt \
--key client.key \
https://&lt;management-plane-api-endpoint&gt;/apis/infrastructure.cluster.x-k8s.io/v1beta1/namespaces/&lt;cluster-namespace&gt;/ociclusters/&lt;cluster-name&gt;/status \
--data '{&quot;status&quot;:{&quot;ready&quot;:true,&quot;failureDomains&quot;:{&quot;1&quot;:{&quot;attributes&quot;:{&quot;AvailabilityDomain&quot;:&quot;zkJl:AP-HYDERABAD-1-AD-1&quot;,&quot;FaultDomain&quot;:&quot;FAULT-DOMAIN-1&quot;},&quot;controlPlane&quot;:true},&quot;2&quot;:{&quot;attributes&quot;:{&quot;AvailabilityDomain&quot;:&quot;zkJl:AP-HYDERABAD-1-AD-1&quot;,&quot;FaultDomain&quot;:&quot;FAULT-DOMAIN-2&quot;},&quot;controlPlane&quot;:true},&quot;3&quot;:{&quot;attributes&quot;:{&quot;AvailabilityDomain&quot;:&quot;zkJl:AP-HYDERABAD-1-AD-1&quot;,&quot;FaultDomain&quot;:&quot;FAULT-DOMAIN-3&quot;}}}}}'
</code></pre>
<p>For 3-AD regions, use the following cURL command to update the status object:</p>
<pre><code class="language-bash">curl -o  -s -X PATCH -H &quot;Accept: application/json, */*&quot; \
-H &quot;Content-Type: application/merge-patch+json&quot; \
--cacert ca.crt \
--cert client.crt \
--key client.key \
https://&lt;management-plane-api-endpoint&gt;/apis/infrastructure.cluster.x-k8s.io/v1beta1/namespaces/&lt;cluster-namespace&gt;/ociclusters/&lt;cluster-name&gt;/status \
--data '{&quot;status&quot;:{&quot;ready&quot;:true,&quot;failureDomains&quot;:{&quot;1&quot;:{&quot;attributes&quot;:{&quot;AvailabilityDomain&quot;:&quot;zkJl:US-ASHBURN-1-AD-1&quot;},&quot;controlPlane&quot;:true},&quot;2&quot;:{&quot;attributes&quot;:{&quot;AvailabilityDomain&quot;:&quot;zkJl:US-ASHBURN-1-AD-2&quot;},&quot;controlPlane&quot;:true},&quot;3&quot;:{&quot;attributes&quot;:{&quot;AvailabilityDomain&quot;:&quot;zkJl:US-ASHBURN-1-AD-3&quot;}}}}}'
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="install-oracle-cloud-infrastructure-cloud-controller-manager"><a class="header" href="#install-oracle-cloud-infrastructure-cloud-controller-manager">Install Oracle Cloud Infrastructure Cloud Controller Manager</a></h1>
<p><a href="https://github.com/oracle/oci-cloud-controller-manager">Oracle Cloud Infrastructure (OCI) Cloud Controller Manager</a> is OCI's implementation of the Kubernetes <a href="https://kubernetes.io/docs/concepts/architecture/cloud-controller/">control plane component</a> that links your Kubernetes cluster to OCI.</p>
<h2 id="configure-authentication-1"><a class="header" href="#configure-authentication-1">Configure authentication</a></h2>
<ol>
<li>
<p>Before downloading the YAML files below, set the version you want to install e.g.</p>
<pre><code class="language-shell">export CCM_RELEASE_VERSION=0.13.0
</code></pre>
</li>
<li>
<p>Download the example configuration file:</p>
<pre><code class="language-shell">curl -L https://raw.githubusercontent.com/oracle/oci-cloud-controller-manager/master/manifests/provider-config-example.yaml -o cloud-provider-example.yaml
</code></pre>
</li>
<li>
<p>Update the values as necessary.</p>
</li>
<li>
<p>Create a secret:</p>
<pre><code class="language-shell">kubectl  create secret generic oci-cloud-controller-manager \
  -n kube-system                                           \
  --from-file=cloud-provider.yaml=cloud-provider-example.yaml
</code></pre>
</li>
<li>
<p>Download the deployment manifests:</p>
</li>
</ol>
<pre><code class="language-shell">curl -L https://github.com/oracle/oci-cloud-controller-manager/releases/download/${CCM_RELEASE_VERSION}/oci-cloud-controller-manager.yaml -o oci-cloud-controller-manager.yaml

curl -L https://github.com/oracle/oci-cloud-controller-manager/releases/download/${CCM_RELEASE_VERSION}/oci-cloud-controller-manager-rbac.yaml -o oci-cloud-controller-manager-rbac.yaml
</code></pre>
<ol>
<li>
<p>Deploy the CCM:</p>
<pre><code class="language-shell">kubectl apply -f oci-cloud-controller-manager.yaml
</code></pre>
</li>
<li>
<p>Deploy the RBAC rules:</p>
<pre><code class="language-shell">kubectl apply -f oci-cloud-controller-manager-rbac.yaml
</code></pre>
</li>
<li>
<p>Check the CCM logs to verify OCI CCM is running correctly:</p>
<pre><code class="language-shell">kubectl -n kube-system get po | grep oci
oci-cloud-controller-manager-ds-k2txq   1/1       Running   0          19s

kubectl -n kube-system logs oci-cloud-controller-manager-ds-k2txq
</code></pre>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="install-csi"><a class="header" href="#install-csi">Install CSI</a></h1>
<p>On Oracle Cloud Infrastructure (OCI), there are two types of storage services available to store persistent data:</p>
<ul>
<li>OCI Block Volume Service</li>
<li>OCI File Storage Service</li>
</ul>
<p>A persistent volume claim (PVC) is a request for storage, which is met by binding the PVC to a persistent volume (PV). A PVC provides an abstraction layer to the underlying storage. CSI drivers for both the Block Volume Service and File Storage Service have been implemented.</p>
<h2 id="configure-authentication-2"><a class="header" href="#configure-authentication-2">Configure Authentication</a></h2>
<ol>
<li>
<p>Download the example configuration file:</p>
<pre><code class="language-shell">curl -L https://raw.githubusercontent.com/oracle/oci-cloud-controller-manager/master/manifests/provider-config-example.yaml -o cloud-provider-example.yaml
</code></pre>
</li>
<li>
<p>Update the values in the <code>cloud-provider-example.yaml</code> as necessary.</p>
</li>
<li>
<p>Create a secret:</p>
<pre><code class="language-shell">kubectl create secret generic oci-volume-provisioner \
 -n kube-system \
 --from-file=config.yaml=provider-config-example.yaml
</code></pre>
</li>
</ol>
<h3 id="install-csi-drivers"><a class="header" href="#install-csi-drivers">Install CSI Drivers</a></h3>
<ol>
<li>
<p>Before downloading the yaml files below, set the version you want to install e.g.</p>
<pre><code class="language-shell">export CCM_RELEASE_VERSION=0.12.0
</code></pre>
</li>
<li>
<p>Download the deployment manifests:</p>
</li>
</ol>
<pre><code class="language-shell">curl -L https://github.com/oracle/oci-cloud-controller-manager/releases/download/${CCM_RELEASE_VERSION}/oci-csi-node-rbac.yaml -o oci-csi-node-rbac.yaml

curl -L https://github.com/oracle/oci-cloud-controller-manager/releases/download/${CCM_RELEASE_VERSION}/oci-csi-controller-driver.yaml -o oci-csi-controller-driver.yaml

curl -L https://github.com/oracle/oci-cloud-controller-manager/releases/download/${CCM_RELEASE_VERSION}/oci-csi-node-driver.yaml -o
oci-csi-node-driver.yaml

curl -L https://github.com/oracle/oci-cloud-controller-manager/releases/download/${CCM_RELEASE_VERSION}/storage-class.yaml -o storage-class.yaml
</code></pre>
<ol>
<li>
<p>Create the RBAC rules:</p>
<pre><code class="language-shell">kubectl apply -f oci-csi-node-rbac.yaml
</code></pre>
</li>
<li>
<p>Deploy the csi-controller-driver. It is provided as a deployment and it has three containers:</p>
<ul>
<li><code>csi-provisioner external-provisioner</code></li>
<li><code>csi-attacher external-attacher</code></li>
<li><code>oci-csi-controller-driver</code></li>
</ul>
</li>
</ol>
<pre><code class="language-shell"> kubectl apply -f oci-csi-controller-driver.yaml
</code></pre>
<ol>
<li>
<p>Deploy the <code>node-driver</code>. It is provided as a daemon set and it has two containers:</p>
<ul>
<li><code>node-driver-registrar</code></li>
<li><code>oci-csi-node-driver</code></li>
</ul>
<pre><code class="language-shell">kubectl apply -f oci-csi-node-driver.yaml
</code></pre>
</li>
<li>
<p>Create the CSI storage class for the Block Volume Service:</p>
<pre><code class="language-shell">kubectl apply -f storage-class.yaml
</code></pre>
</li>
<li>
<p>Verify the <code>oci-csi-controller-driver</code> and <code>oci-csi-node-controller</code> are running in your cluster:</p>
<pre><code class="language-shell">kubectl -n kube-system get po | grep csi-oci-controller
kubectl -n kube-system get po | grep csi-oci-node
</code></pre>
</li>
</ol>
<h3 id="provision-pvcs"><a class="header" href="#provision-pvcs">Provision PVCs</a></h3>
<p>Follow the guides below to create PVCs based on the service you require:</p>
<ul>
<li>
<p><a href="gs/pvc-pvc-bv.html">Provision a PVC on the Block Volume Service</a></p>
</li>
<li>
<p><a href="gs/pvc-fss.html">Provision a PVC on the File Storage Service</a></p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="provision-a-pvc-on-the-block-volume-service"><a class="header" href="#provision-a-pvc-on-the-block-volume-service">Provision a PVC on the Block Volume Service</a></h1>
<p>The Oracle Cloud Infrastructure Block Volume service (the Block Volume service) provides persistent, durable, and high-performance block storage for your data.</p>
<h2 id="create-a-block-volume-dynamically-using-a-new-pvc"><a class="header" href="#create-a-block-volume-dynamically-using-a-new-pvc">Create a block volume dynamically using a new PVC</a></h2>
<p>If the cluster administrator has not created any suitable PVs that match the PVC request, you can dynamically provision a block volume using the CSI plugin specified by the oci-bv storage class's definition (provisioner: blockvolume.csi.oraclecloud.com).</p>
<ol>
<li>
<p>Define a PVC in a yaml file (<code>csi-bvs-pvc.yaml</code>)as below:</p>
<pre><code class="language-yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
name: mynginxclaim
spec:
 storageClassName: &quot;oci-bv&quot;
 accessModes:
   - ReadWriteOnce
 resources:
   requests:
     storage: 50Gi
</code></pre>
</li>
<li>
<p>Apply the manifest to create the PVC</p>
<pre><code class="language-shell">kubectl create -f  csi-bvs-pvc.yaml
</code></pre>
</li>
<li>
<p>Verify that the PVC has been created:</p>
<pre><code class="language-shell">kubectl get pvc
</code></pre>
</li>
<li>
<p>The output from the above command shows the current status of the PVC:</p>
<pre><code class="language-shell">NAME               STATUS   VOLUME   CAPACITY   ACCESSMODES   STORAGECLASS   AGE
mynginxclaim       Pending                                    oci-bv         4m
</code></pre>
<p>The PVC has a status of Pending because the <code>oci-bv</code> storage class's definition includes <code>volumeBindingMode: WaitForFirstConsumer</code>.</p>
</li>
<li>
<p>You can use this PVC when creating other objects, such as pods. For example, you could create a new pod from the following pod definition, which instructs the system to use the <code>mynginxclaim</code> PVC as the NGINX volume, which is mounted by the pod at <code>/data</code>.</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
 name: nginx
spec:
 containers:
   - name: nginx
     image: nginx:latest
     ports:
       - name: http
         containerPort: 80
     volumeMounts:
       - name: data
         mountPath: /usr/share/nginx/html
 volumes:
   - name: data
     persistentVolumeClaim:
     claimName: mynginxclaim
</code></pre>
</li>
<li>
<p>After creating the new pod, verify that the PVC has been bound to a new persistent volume (PV):</p>
<pre><code class="language-shell">kubectl get pvc
</code></pre>
<p>The output from the above command confirms that the PVC has been bound:</p>
<pre><code class="language-shell">NAME               STATUS    VOLUME                               CAPACITY   ACCESSMODES   STORAGECLASS   AGE
mynginxclaim       Bound     ocid1.volume.oc1.iad.&lt;unique_ID&gt;     50Gi       RWO           oci-bv         4m
</code></pre>
</li>
<li>
<p>Verify that the pod is using the new PVC:</p>
<pre><code class="language-shell">kubectl describe pod nginx
</code></pre>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="provision-a-pvc-on-the-file-storage-service"><a class="header" href="#provision-a-pvc-on-the-file-storage-service">Provision a PVC on the File Storage Service</a></h1>
<p>The Oracle Cloud Infrastructure File Storage service provides a durable, scalable, distributed, enterprise-grade network file system.</p>
<h2 id="provision-pvcs-on-the-file-storage-service-fss"><a class="header" href="#provision-pvcs-on-the-file-storage-service-fss">Provision PVCs on the File Storage Service (FSS)</a></h2>
<p>Provisioning PVCs on FSS consists of 3 steps:</p>
<ol>
<li>Create an FSS instance and a mount target</li>
<li>Define and create a PV backed by FSS</li>
<li>Define and create a PVC provisioned by the PV</li>
</ol>
<h3 id="configure-the-vcn-and-create-an-fss"><a class="header" href="#configure-the-vcn-and-create-an-fss">Configure the VCN and create an FSS</a></h3>
<ol>
<li>Choose your <a href="https://docs.oracle.com/en-us/iaas/Content/File/Tasks/securitylistsfilestorage.htm#File_Storage_Security_Rule_Scenarios">deployment scenario</a>:
<ol>
<li>Mount target and worker nodes in the same subnet</li>
<li>Mount target and worker nodes in different subnets</li>
<li>Mount target and instance use in-transit encryption</li>
</ol>
</li>
<li>Implement <a href="https://docs.oracle.com/en-us/iaas/Content/File/Tasks/securitylistsfilestorage.htm#Setting2">security rules</a> based on your deployment scenario</li>
<li><a href="https://docs.oracle.com/en-us/iaas/Content/File/Tasks/creatingfilesystems.htm#createfs">Create a FSS instance</a></li>
</ol>
<h3 id="define-and-create-a-pv-backed-by-fss"><a class="header" href="#define-and-create-a-pv-backed-by-fss">Define and create a PV backed by FSS</a></h3>
<ol>
<li>
<p>Create a yaml file (<code>fss-pv.yaml</code>) to define the PV:</p>
<pre><code class="language-yaml">apiVersion: v1
kind: PersistentVolume
metadata:
  name: fss-pv
spec:
 capacity:
   storage: 50Gi
 volumeMode: Filesystem
 accessModes:
   - ReadWriteMany
 persistentVolumeReclaimPolicy: Retain
 csi:
   driver: fss.csi.oraclecloud.com
   volumeHandle: ocid1.filesystem.oc1.iad.aaaa______j2xw:10.0.0.6:/FileSystem1
</code></pre>
</li>
<li>
<p>In the yaml file, set:</p>
<ol>
<li><code>driver</code> value to: <code>fss.csi.oraclecloud.com</code></li>
<li><code>volumeHandle</code> value to: <code>&lt;FileSystemOCID&gt;:&lt;MountTargetIP&gt;:&lt;path&gt;</code></li>
</ol>
<p>The <code>&lt;FileSystemOCID&gt;</code> is the OCID of the file system defined in the File Storage service, the <code>&lt;MountTargetIP&gt;</code> is the IP address assigned to the mount target and the <code>&lt;path&gt;</code> is the mount path to the file system relative to the mount target IP address, starting with a slash.</p>
</li>
<li>
<p>Create the PV from the manifest file:</p>
<pre><code class="language-shell">kubectl create -f fss-pv.yaml
</code></pre>
</li>
</ol>
<h3 id="define-and-create-a-pvc-provisioned-by-the-pv"><a class="header" href="#define-and-create-a-pvc-provisioned-by-the-pv">Define and create a PVC provisioned by the PV</a></h3>
<ol>
<li>
<p>Create a manifest file (<code>fss-pvc.yaml</code>) to define the PVC:</p>
<pre><code class="language-yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: fss-pvc
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: &quot;&quot;
  resources:
    requests:
      storage: 50Gi
  volumeName: fss-pv
</code></pre>
</li>
<li>
<p>In the YAML file, set:</p>
<ol>
<li><code>storageClassName</code> to <code>&quot;&quot;</code></li>
<li><code>volumeName</code> to the name of the PV created earlier</li>
</ol>
</li>
<li>
<p>Create the PVC from the manifest file:</p>
<pre><code class="language-shell">kubectl create -f fss-pvc.yaml
</code></pre>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="networking-guide"><a class="header" href="#networking-guide">Networking Guide</a></h1>
<p>This section contains information about the networking aspects of Cluster API Provider OCI.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="default-network-infrastructure"><a class="header" href="#default-network-infrastructure">Default Network Infrastructure</a></h1>
<p>The diagram below depicts the networking architecture for a public workload cluster created in a region such as <strong>US West (Phoenix)</strong>.
<img src="networking/../images/clusteroci.svg" alt="Networking Architecture - Workload Cluster" /></p>
<p>Each workload cluster requires an <a href="networking/../reference/glossary.html#vcn">OCI Virtual Cloud Network (VCN)</a> which houses all the resources created for the workload cluster. The default VCN has the following resources:</p>
<ul>
<li>
<p>Gateways:</p>
<ol>
<li>An <a href="networking/../reference/glossary.html#internet-gateway">Internet Gateway</a></li>
<li>A <a href="networking/../reference/glossary.html#nat-gateway">NAT Gateway</a></li>
<li>A <a href="networking/../reference/glossary.html#service-gateway">Service Gateway</a></li>
</ol>
</li>
<li>
<p>Route Tables:</p>
<ol>
<li>A route table for <a href="https://docs.oracle.com/en-us/iaas/Content/Network/Concepts/overview.htm#Public">public subnets</a> which will route stateful traffic to and from the Internet Gateway</li>
<li>A route table for <a href="https://docs.oracle.com/en-us/iaas/Content/Network/Concepts/overview.htm#Public">private subnets</a> which will route stateful traffic to and from the NAT and Service Gateways</li>
</ol>
</li>
<li>
<p>Subnets:</p>
<ol>
<li>A public Control plane endpoint subnet which houses an OCI Load Balancer. The load balancer acts as a reverse proxy for the Kubernetes API Server.</li>
<li>A private Control plane subnet which houses the Control plane nodes. The Control plane nodes run the Kubernetes Control plane components such as the API Server and the Control plane pods.</li>
<li>A public subnet which houses the service load balancers.</li>
<li>A private subnet which houses the worker nodes.</li>
</ol>
</li>
<li>
<p>Network Security Groups (NSG):</p>
<ol>
<li>An NSG for the Control plane endpoint (Control plane Endpoint NSG)</li>
<li>An NSG for the Kubernetes Control plane nodes (Control plane NSG)</li>
<li>An NSG for the service load balancers (Worker NSG)</li>
<li>An NSG for the Kubernetes worker nodes (Service Load Balancers NSG)</li>
</ol>
</li>
</ul>
<p>The sections below list the security rules required for the NSGs in each of the following <a href="networking/../reference/glossary.html#cni">CNI</a> providers:</p>
<ul>
<li><a href="networking/calico.html">Using Calico</a></li>
<li><a href="networking/antrea.html">Using Antrea</a></li>
</ul>
<p>Currently, the following providers have been tested and verified to work:</p>
<table><thead><tr><th>CNI</th><th>CNI Version</th><th>Kubernetes Version</th><th>CAPOCI Version</th></tr></thead><tbody>
<tr><td><a href="networking/calico.html">Calico</a></td><td>3.21</td><td>1.20.10</td><td>0.1</td></tr>
<tr><td><a href="networking/antrea.html">Antrea</a></td><td></td><td>1.20.10</td><td>0.1</td></tr>
</tbody></table>
<p>If you have tested an alternative CNI provider and verified it to work, please send us a PR to add it to the list. Your PR for your tested CNI provider should include the following:</p>
<ul>
<li>CNI provider version tested</li>
<li>Documentation of NSG rules required</li>
<li>A YAML template for your tested provider. See the <a href="networking/../../../templates/cluster-template-antrea.yaml">Antrea template</a> as an example.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="using-calico"><a class="header" href="#using-calico">Using Calico</a></h1>
<p>This section lists the security rules that must be implemented in the network security groups (NSGs) in order to use <a href="https://www.tigera.io/project-calico/">Calico</a> as a CNI provider.</p>
<h2 id="control-plane-endpoint-nsg"><a class="header" href="#control-plane-endpoint-nsg">Control plane endpoint NSG</a></h2>
<p>The control plane endpoint NSG will be attached to the OCI load balancer. The egress and ingress rules are listed below.</p>
<h3 id="control-plane-endpoint-nsg-egress-rules"><a class="header" href="#control-plane-endpoint-nsg-egress-rules">Control plane endpoint NSG egress rules</a></h3>
<table><thead><tr><th>Destination Type</th><th>Destination</th><th>Destination Port</th><th>Protocol</th><th>Description</th></tr></thead><tbody>
<tr><td>CIDR block</td><td>10.0.0.0/29</td><td>6443</td><td>TCP</td><td>Allow HTTPS traffic to Control plane for Kubernetes API server access</td></tr>
</tbody></table>
<h3 id="control-plane-endpoint-nsg-ingress-rules"><a class="header" href="#control-plane-endpoint-nsg-ingress-rules">Control plane endpoint NSG ingress rules</a></h3>
<table><thead><tr><th>Source Type</th><th>Source</th><th>Destination Port</th><th>Protocol</th><th>Description</th></tr></thead><tbody>
<tr><td>CIDR block</td><td>0.0.0.0/0</td><td>6443</td><td>TCP</td><td>Allow public access to endpoint OCI load balancer</td></tr>
</tbody></table>
<h2 id="control-plane-nsg"><a class="header" href="#control-plane-nsg">Control plane NSG</a></h2>
<p>The OCI compute instances running the Kubernetes control plane components will be attached to this NSG.</p>
<h3 id="control-plane-nsg-egress-rules"><a class="header" href="#control-plane-nsg-egress-rules">Control plane NSG egress rules</a></h3>
<table><thead><tr><th>Destination Type</th><th>Destination</th><th>Destination Port</th><th>Protocol</th><th>Description</th></tr></thead><tbody>
<tr><td>CIDR block</td><td>0.0.0.0/0</td><td>All</td><td>ALL</td><td>Control plane access to Internet to pull images</td></tr>
</tbody></table>
<h4 id="ingress-rules"><a class="header" href="#ingress-rules">Ingress Rules</a></h4>
<table><thead><tr><th>Source Type</th><th>Source</th><th>Destination Port</th><th>Protocol</th><th>Description</th></tr></thead><tbody>
<tr><td>CIDR block</td><td>10.0.0.8/29</td><td>6443</td><td>TCP</td><td>Kubernetes API endpoint to Kubernetes control plane communication</td></tr>
<tr><td>CIDR block</td><td>10.0.0.0/29</td><td>6443</td><td>TCP</td><td>Control plane to control plane (API server port) communication</td></tr>
<tr><td>CIDR block</td><td>10.0.64.0/20</td><td>6443</td><td>TCP</td><td>Worker Node to Kubernetes control plane (API Server) communication</td></tr>
<tr><td>CIDR block</td><td>10.0.0.0/29</td><td>2379</td><td>TCP</td><td>etcd client communication</td></tr>
<tr><td>CIDR block</td><td>10.0.0.0/29</td><td>2380</td><td>TCP</td><td>etcd peer communication</td></tr>
<tr><td>CIDR block</td><td>10.0.0.0/29</td><td>179</td><td>TCP</td><td>Calico networking (BGP)</td></tr>
<tr><td>CIDR block</td><td>10.0.64.0/20</td><td>179</td><td>TCP</td><td>Calico networking (BGP)</td></tr>
<tr><td>CIDR block</td><td>10.0.0.0/29</td><td></td><td>IP-in-IP</td><td>Calico networking with IP-in-IP enabled</td></tr>
<tr><td>CIDR block</td><td>10.0.64.0/20</td><td></td><td>IP-in-IP</td><td>Calico networking with IP-in-IP enabled</td></tr>
<tr><td>CIDR block</td><td>10.0.0.0/16</td><td></td><td>ICMP Type 3, Code 4</td><td>MTU Path discovery</td></tr>
<tr><td>CIDR block</td><td>0.0.0.0/0</td><td>22</td><td>TCP</td><td>Inbound SSH traffic to control plane nodes</td></tr>
</tbody></table>
<h2 id="worker-nsg"><a class="header" href="#worker-nsg">Worker NSG</a></h2>
<p>The OCI compute instances which running as Kubernetes worker nodes will be attached to this NSG.</p>
<h3 id="worker-nsg-egress-rules"><a class="header" href="#worker-nsg-egress-rules">Worker NSG egress rules</a></h3>
<table><thead><tr><th>Destination Type</th><th>Destination</th><th>Destination Port</th><th>Protocol</th><th>Description</th></tr></thead><tbody>
<tr><td>CIDR block</td><td>0.0.0.0/0</td><td>All</td><td>All</td><td>Worker node access to Internet to pull images</td></tr>
</tbody></table>
<h3 id="worker-nsg-ingress-rules"><a class="header" href="#worker-nsg-ingress-rules">Worker NSG ingress rules</a></h3>
<table><thead><tr><th>Source Type</th><th>Source</th><th>Destination Port</th><th>Protocol</th><th>Description</th></tr></thead><tbody>
<tr><td>CIDR block</td><td>10.0.0.32/27</td><td>32000-32767</td><td>TCP</td><td>Allow incoming traffic from service load balancers (NodePort Communication)</td></tr>
<tr><td>CIDR block</td><td>10.0.0.0/29</td><td>10250</td><td>TCP</td><td>Control plane to worker node (Kubelet Communication)</td></tr>
<tr><td>CIDR block</td><td>10.0.64.0/20</td><td>10250</td><td>TCP</td><td>Worker nodes to worker node (Kubelet Communication)</td></tr>
<tr><td>CIDR block</td><td>10.0.0.0/29</td><td>179</td><td>TCP</td><td>Calico networking (BGP)</td></tr>
<tr><td>CIDR block</td><td>10.0.64.0/20</td><td>179</td><td>TCP</td><td>Calico networking (BGP)</td></tr>
<tr><td>CIDR block</td><td>10.0.0.0/29</td><td></td><td>IP-in-IP</td><td>Calico networking with IP-in-IP enabled</td></tr>
<tr><td>CIDR block</td><td>10.0.64.0/20</td><td></td><td>IP-in-IP</td><td>Calico networking with IP-in-IP enabled</td></tr>
<tr><td>CIDR block</td><td>10.0.0.0/16</td><td></td><td>ICMP Type 3, Code 4</td><td>MTU Path discovery</td></tr>
<tr><td>CIDR block</td><td>0.0.0.0/0</td><td>22</td><td>TCP</td><td>Inbound SSH traffic to worker nodes</td></tr>
</tbody></table>
<h2 id="service-load-balancers-nsg"><a class="header" href="#service-load-balancers-nsg">Service Load Balancers NSG</a></h2>
<p>OCI load balancers created as part of Kubernetes services of type LoadBalancer will be attached to this NSG.</p>
<h3 id="service-load-balancers-nsg-egress-rules"><a class="header" href="#service-load-balancers-nsg-egress-rules">Service Load Balancers NSG egress rules</a></h3>
<table><thead><tr><th>Destination Type</th><th>Destination</th><th>Destination Port</th><th>Protocol</th><th>Description</th></tr></thead><tbody>
<tr><td>CIDR block</td><td>10.0.64.0/20</td><td>32000-32767</td><td>TCP</td><td>Allow access to NodePort services from Service Load balancers</td></tr>
</tbody></table>
<h3 id="service-load-balancers-nsg-ingress-rules"><a class="header" href="#service-load-balancers-nsg-ingress-rules">Service Load Balancers NSG ingress rules</a></h3>
<table><thead><tr><th>Source Type</th><th>Source</th><th>Destination Port</th><th>Protocol</th><th>Description</th></tr></thead><tbody>
<tr><td>CIDR block</td><td>0.0.0.0/0</td><td>80, 443</td><td>TCP</td><td>Allow incoming traffic to services</td></tr>
</tbody></table>
<div style="break-before: page; page-break-before: always;"></div><h1 id="using-antrea"><a class="header" href="#using-antrea">Using Antrea</a></h1>
<p>This section lists the security rules that must be implemented in the Network Security Groups (NSGs) in order to use <a href="https://antrea.io/docs/">Antrea</a> as a CNI provider.</p>
<h2 id="control-plane-endpoint-nsg-1"><a class="header" href="#control-plane-endpoint-nsg-1">Control plane endpoint NSG</a></h2>
<p>The Control plane Endpoint NSG will be attached to the OCI Load Balancer. The egress and ingress rules are listed below.</p>
<h3 id="control-plane-endpoint-nsg-egress-rules-1"><a class="header" href="#control-plane-endpoint-nsg-egress-rules-1">Control plane endpoint NSG egress rules</a></h3>
<table><thead><tr><th>Destination Type</th><th>Destination</th><th>Destination Port</th><th>Protocol</th><th>Description</th></tr></thead><tbody>
<tr><td>CIDR Block</td><td>10.0.0.0/29</td><td>6443</td><td>TCP</td><td>Allow HTTPS Traffic to Control plane for Kubernetes API Server access</td></tr>
</tbody></table>
<h3 id="control-plane-endpoint-nsg-ingress-rules-1"><a class="header" href="#control-plane-endpoint-nsg-ingress-rules-1">Control plane endpoint NSG ingress rules</a></h3>
<table><thead><tr><th>Source Type</th><th>Source</th><th>Destination Port</th><th>Protocol</th><th>Description</th></tr></thead><tbody>
<tr><td>CIDR Block</td><td>0.0.0.0/0</td><td>6443</td><td>TCP</td><td>Allow public access to endpoint OCI Load Balancer</td></tr>
</tbody></table>
<h2 id="control-plane-nsg-1"><a class="header" href="#control-plane-nsg-1">Control plane NSG</a></h2>
<p>The OCI Compute instances running the Kubernetes Control plane components will be attached to this NSG.</p>
<h3 id="control-plane-nsg-egress-rules-1"><a class="header" href="#control-plane-nsg-egress-rules-1">Control plane NSG egress rules</a></h3>
<table><thead><tr><th>Destination Type</th><th>Destination</th><th>Destination Port</th><th>Protocol</th><th>Description</th></tr></thead><tbody>
<tr><td>CIDR Block</td><td>0.0.0.0/0</td><td>All</td><td>ALL</td><td>Control plane access to Internet to pull images</td></tr>
</tbody></table>
<h3 id="control-plane-nsg-ingress-rules"><a class="header" href="#control-plane-nsg-ingress-rules">Control plane NSG ingress rules</a></h3>
<table><thead><tr><th>Source Type</th><th>Source</th><th>Destination Port</th><th>Protocol</th><th>Description</th></tr></thead><tbody>
<tr><td>CIDR Block</td><td>10.0.0.8/29</td><td>6443</td><td>TCP</td><td>Kubernetes API endpoint to Kubernetes Control plane communication</td></tr>
<tr><td>CIDR Block</td><td>10.0.0.0/29</td><td>6443</td><td>TCP</td><td>Control plane to Control plane (API Server port) communication</td></tr>
<tr><td>CIDR Block</td><td>10.0.64.0/20</td><td>6443</td><td>TCP</td><td>Worker Node to Kubernetes Control plane (API Server port)communication</td></tr>
<tr><td>CIDR Block</td><td>10.0.0.0/29</td><td>2379</td><td>TCP</td><td>etcd client communication</td></tr>
<tr><td>CIDR Block</td><td>10.0.0.0/29</td><td>2380</td><td>TCP</td><td>etcd peer communication</td></tr>
<tr><td>CIDR Block</td><td>10.0.0.0/29</td><td>10349</td><td>TCP</td><td>Antrea Service</td></tr>
<tr><td>CIDR Block</td><td>10.0.64.0/20</td><td>10349</td><td>TCP</td><td>Antrea Service</td></tr>
<tr><td>CIDR Block</td><td>10.0.0.0/29</td><td>6081</td><td>UDP</td><td>Geneve Service</td></tr>
<tr><td>CIDR Block</td><td>10.0.64.0/20</td><td>6081</td><td>UDP</td><td>Geneve Service</td></tr>
<tr><td>CIDR Block</td><td>10.0.0.0/16</td><td></td><td>ICMP Type 3, Code 4</td><td>Path discovery</td></tr>
<tr><td>CIDR Block</td><td>0.0.0.0/0</td><td>22</td><td>TCP</td><td>Inbound SSH traffic to Control plane nodes</td></tr>
</tbody></table>
<h2 id="worker-nsg-1"><a class="header" href="#worker-nsg-1">Worker NSG</a></h2>
<p>The OCI Compute instances which running as Kubernetes worker nodes will be attached to this NSG.</p>
<h3 id="worker-nsg-egress-rules-1"><a class="header" href="#worker-nsg-egress-rules-1">Worker NSG egress rules</a></h3>
<table><thead><tr><th>Destination Type</th><th>Destination</th><th>Destination Port</th><th>Protocol</th><th>Description</th></tr></thead><tbody>
<tr><td>CIDR Block</td><td>0.0.0.0/0</td><td>All</td><td>All</td><td>Worker Nodes access to Internet to pull images</td></tr>
</tbody></table>
<h3 id="worker-nsg-ingress-rules-1"><a class="header" href="#worker-nsg-ingress-rules-1">Worker NSG ingress rules</a></h3>
<table><thead><tr><th>Source Type</th><th>Source</th><th>Destination Port</th><th>Protocol</th><th>Description</th></tr></thead><tbody>
<tr><td>CIDR Block</td><td>10.0.0.32/27</td><td>32000-32767</td><td>TCP</td><td>Allow incoming traffic from service load balancers (NodePort Communication)</td></tr>
<tr><td>CIDR Block</td><td>10.0.0.0/29</td><td>10250</td><td>TCP</td><td>Control plane to worker node (Kubelet Communication)</td></tr>
<tr><td>CIDR Block</td><td>10.0.64.0/20</td><td>10250</td><td>TCP</td><td>Worker nodes to worker node (Kubelet Communication)</td></tr>
<tr><td>CIDR Block</td><td>10.0.0.0/29</td><td>10349</td><td>TCP</td><td>Antrea Service</td></tr>
<tr><td>CIDR Block</td><td>10.0.64.0/20</td><td>10349</td><td>TCP</td><td>Antrea Service</td></tr>
<tr><td>CIDR Block</td><td>10.0.0.0/29</td><td>6081</td><td>UDP</td><td>Geneve Service</td></tr>
<tr><td>CIDR Block</td><td>10.0.64.0/20</td><td>6081</td><td>UDP</td><td>Geneve Service</td></tr>
<tr><td>CIDR Block</td><td>10.0.0.0/16</td><td></td><td>ICMP Type 3, Code 4</td><td>Path discovery</td></tr>
<tr><td>CIDR Block</td><td>0.0.0.0/0</td><td>22</td><td>TCP</td><td>Inbound SSH traffic to worker nodes</td></tr>
</tbody></table>
<h2 id="service-load-balancers-nsg-1"><a class="header" href="#service-load-balancers-nsg-1">Service load balancers NSG</a></h2>
<p>OCI load balancers created as part of Kubernetes Services of type LoadBalancer will be attached to this NSG.</p>
<h3 id="service-load-balancers-nsg-egress-rules-1"><a class="header" href="#service-load-balancers-nsg-egress-rules-1">Service load balancers NSG egress rules</a></h3>
<table><thead><tr><th>Destination Type</th><th>Destination</th><th>Destination Port</th><th>Protocol</th><th>Description</th></tr></thead><tbody>
<tr><td>CIDR Block</td><td>10.0.64.0/20</td><td>32000-32767</td><td>TCP</td><td>Allow access to NodePort services from Service Load balancers</td></tr>
</tbody></table>
<h3 id="service-load-balancers-nsg-ingress-rules-1"><a class="header" href="#service-load-balancers-nsg-ingress-rules-1">Service load balancers NSG ingress rules</a></h3>
<table><thead><tr><th>Source Type</th><th>Source</th><th>Destination Port</th><th>Protocol</th><th>Description</th></tr></thead><tbody>
<tr><td>CIDR Block</td><td>0.0.0.0/0</td><td>80, 443</td><td>TCP</td><td>Allow incoming traffic to services</td></tr>
</tbody></table>
<div style="break-before: page; page-break-before: always;"></div><h1 id="custom-networking"><a class="header" href="#custom-networking">Custom networking</a></h1>
<p>The <a href="networking/infrastructure.html">default networking</a> can be modified to achieve the following:</p>
<ul>
<li>your own CIDR range for VCN. This is useful if you want to perform peering with another VCN or another cloud provider and you need to avoid IP Overlapping</li>
<li>your own custom security rules using <a href="networking/../reference/glossary.html#nsg">NSGs</a>. This is useful if you want to use your own CNI provider and it has a different security posture than the default</li>
<li>your own custom security rules using network security lists</li>
<li>change the masks and name of your different subnets. This is useful to either expand or constrain the size of your subnets as well as to use your own preferred naming convention</li>
</ul>
<p>The <code>OCICluster</code> spec in the cluster templates can be modified to customize the network spec.</p>
<h2 id="example-spec-for-custom-cidr-range"><a class="header" href="#example-spec-for-custom-cidr-range">Example spec for custom CIDR range</a></h2>
<p>The spec below shows how to change the CIDR range of the VCN from the default <code>10.0.0.0/16</code> to <code>172.16.0.0/16</code>.</p>
<pre><code class="language-yaml">apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: OCICluster
metadata:
  name: &quot;${CLUSTER_NAME}&quot;
spec:
  networkSpec:
    vcn:
      name: ${CLUSTER_NAME}
      cidr: &quot;172.16.0.0/16&quot;
      subnets:
        - name: ep-subnet
          role: control-plane-endpoint
          type: public
          cidr: &quot;172.16.0.0/28&quot;
        - name: cp-mc-subnet
          role: control-plane
          type: private
          cidr: &quot;172.16.5.0/28&quot;
        - name: worker-subnet
          role: worker
          type: private
          cidr: &quot;172.16.10.0/24&quot;
        - name: svc-lb-subnet
          role: service-lb
          type: public
          cidr: &quot;172.16.20.0/24&quot;
</code></pre>
<h2 id="example-spec-to-modify-default-nsg-security-rules"><a class="header" href="#example-spec-to-modify-default-nsg-security-rules">Example spec to modify default NSG security rules</a></h2>
<p>The spec below shows how to change the default NSG rules.</p>
<pre><code class="language-yaml">---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: OCICluster
metadata:
  name: &quot;${CLUSTER_NAME}&quot;
spec:
  networkSpec:
    vcn:
      name: ${CLUSTER_NAME}
      cidr: &quot;172.16.0.0/16&quot;
      networkSecurityGroups:
        - name: ep-nsg
          role: control-plane-endpoint
          egressRules:
            - egressRule:
                isStateless: false
                destination: &quot;172.16.5.0/28&quot;
                protocol: &quot;6&quot;
                destinationType: &quot;CIDR_BLOCK&quot;
                description: &quot;All traffic to control plane nodes&quot;
                tcpOptions:
                  destinationPortRange:
                    max: 6443
                    min: 6443
          ingressRules:
            - ingressRule:
                isStateless: false
                source: &quot;0.0.0.0/0&quot;
                protocol: &quot;6&quot;
                sourceType: &quot;CIDR_BLOCK&quot;
                description: &quot;External access to Kubernetes API endpoint&quot;
                tcpOptions:
                  destinationPortRange:
                    max: 6443
                    min: 6443
            - ingressRule:
                isStateless: false
                source: &quot;172.16.5.0/28&quot;
                protocol: &quot;6&quot;
                sourceType: &quot;CIDR_BLOCK&quot;
                description: &quot;Control plane worker nodes to API Server endpoint&quot;
            - ingressRule:
                isStateless: false
                source: &quot;0.0.0.0/0&quot;
                protocol: &quot;6&quot;
                sourceType: &quot;CIDR_BLOCK&quot;
                description: &quot;SSH access&quot;
                tcpOptions:
                  destinationPortRange:
                    max: 22
                    min: 22
        - name: cp-mc-nsg
          role: control-plane
          egressRules:
            - egressRule:
                isStateless: false
                destination: &quot;0.0.0.0/0&quot;
                protocol: &quot;6&quot;
                destinationType: &quot;CIDR_BLOCK&quot;
                description: &quot;control plane machine access to internet&quot;
          ingressRules:
            - ingressRule:
                isStateless: false
                source: &quot;172.16.0.0/16&quot;
                protocol: &quot;all&quot;
                sourceType: &quot;CIDR_BLOCK&quot;
                description: &quot;Allow inter vcn communication&quot;
            - ingressRule:
                isStateless: false
                source: &quot;0.0.0.0/0&quot;
                protocol: &quot;6&quot;
                sourceType: &quot;CIDR_BLOCK&quot;
                description: &quot;SSH access&quot;
                tcpOptions:
                  destinationPortRange:
                    max: 22
                    min: 22
        - name: worker-nsg
          role: worker
          egressRules:
            - egressRule:
                isStateless: false
                destination: &quot;0.0.0.0/0&quot;
                protocol: &quot;6&quot;
                destinationType: &quot;CIDR_BLOCK&quot;
                description: &quot;Worker Nodes access to Internet&quot;
          ingressRules:
            - ingressRule:
                isStateless: false
                source: &quot;172.16.0.0/16&quot;
                protocol: &quot;all&quot;
                sourceType: &quot;CIDR_BLOCK&quot;
                description: &quot;Allow inter vcn communication&quot;
        - name: service-lb-nsg
          role: service-lb
          ingressRules:
            - ingressRule:
                isStateless: false
                source: &quot;172.16.0.0/16&quot;
                protocol: &quot;all&quot;
                sourceType: &quot;CIDR_BLOCK&quot;
                description: &quot;Allow ingress from vcn subnets&quot;
      subnets:
        - name: ep-subnet
          role: control-plane-endpoint
          type: public
          cidr: &quot;172.16.0.0/28&quot;
        - name: cp-mc-subnet
          role: control-plane
          type: private
          cidr: &quot;172.16.5.0/28&quot;
        - name: worker-subnet
          role: worker
          type: private
          cidr: &quot;172.16.10.0/24&quot;
        - name: svc-lb-subnet
          role: service-lb
          type: public
          cidr: &quot;172.16.20.0/24&quot;
</code></pre>
<h2 id="example-spec-to-use-security-lists-instead-of-network-security-groups"><a class="header" href="#example-spec-to-use-security-lists-instead-of-network-security-groups">Example spec to use Security Lists instead of Network Security Groups</a></h2>
<p>The spec below shows how to implement the security posture using security lists instead of NSGs.</p>
<pre><code class="language-yaml">---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: OCICluster
metadata:
  name: &quot;${CLUSTER_NAME}&quot;
spec:
  networkSpec:
    vcn:
      name: ${CLUSTER_NAME}
      subnets:
        - name: ep-subnet
          role: control-plane-endpoint
          type: public
          securityList:
            name: ep-seclist
            egressRules:
              - destination: &quot;10.0.0.0/29&quot;
                protocol: &quot;6&quot;
                destinationType: &quot;CIDR_BLOCK&quot;
                description: &quot;All traffic to control plane nodes&quot;
                tcpOptions:
                  destinationPortRange:
                    max: 6443
                    min: 6443
            ingressRules:
              - source: &quot;0.0.0.0/0&quot;
                protocol: &quot;6&quot;
                sourceType: &quot;CIDR_BLOCK&quot;
                description: &quot;External access to Kubernetes API endpoint&quot;
                tcpOptions:
                  destinationPortRange:
                    max: 6443
                    min: 6443
              - source: &quot;10.0.0.0/29&quot;
                protocol: &quot;6&quot;
                sourceType: &quot;CIDR_BLOCK&quot;
                description: &quot;Control plane worker nodes to API Server endpoint&quot;
              - source: &quot;0.0.0.0/0&quot;
                protocol: &quot;6&quot;
                sourceType: &quot;CIDR_BLOCK&quot;
                description: &quot;SSH access&quot;
                tcpOptions:
                  destinationPortRange:
                    max: 22
                    min: 22
        - name: cp-mc-subnet
          role: control-plane
          type: private
          securityList:
            name: cp-mc-seclist
            egressRules:
              - destination: &quot;0.0.0.0/0&quot;
                protocol: &quot;6&quot;
                destinationType: &quot;CIDR_BLOCK&quot;
                description: &quot;control plane machine access to internet&quot;
            ingressRules:
              - source: &quot;10.0.0.0/16&quot;
                protocol: &quot;all&quot;
                sourceType: &quot;CIDR_BLOCK&quot;
                description: &quot;Allow inter vcn communication&quot;
              - source: &quot;0.0.0.0/0&quot;
                protocol: &quot;6&quot;
                sourceType: &quot;CIDR_BLOCK&quot;
                description: &quot;SSH access&quot;
                tcpOptions:
                  destinationPortRange:
                    max: 22
                    min: 22
        - name: worker-subnet
          role: worker
          type: private
          securityList:
            name: node-seclist
            egressRules:
              - destination: &quot;0.0.0.0/0&quot;
                protocol: &quot;6&quot;
                destinationType: &quot;CIDR_BLOCK&quot;
                description: &quot;Worker Nodes access to Internet&quot;
            ingressRules:
              - source: &quot;10.0.0.0/16&quot;
                protocol: &quot;all&quot;
                sourceType: &quot;CIDR_BLOCK&quot;
                description: &quot;Allow inter vcn communication&quot;
        - name: svc-lb-subnet
          role: service-lb
          type: public
          securityList:
            name: service-lb-seclist
            ingressRules:
              - source: &quot;10.0.0.0/16&quot;
                protocol: &quot;all&quot;
                sourceType: &quot;CIDR_BLOCK&quot;
                description: &quot;Allow ingress from vcn subnets&quot;
</code></pre>
<p>Related documentation: <a href="https://docs.oracle.com/en-us/iaas/Content/Network/Concepts/securityrules.htm#comparison">comparison of Security Lists and Network Security Groups</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="reference"><a class="header" href="#reference">Reference</a></h1>
<p>This section contains various resources that define the Cluster API for OCI project.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="table-of-contents"><a class="header" href="#table-of-contents">Table of Contents</a></h1>
<p><a href="reference/glossary.html#a">A</a> | <a href="reference/glossary.html#b">B</a> | <a href="reference/glossary.html#c">C</a> | <a href="reference/glossary.html#d">D</a> | <a href="reference/glossary.html#h">H</a> | <a href="reference/glossary.html#i">I</a> | <a href="reference/glossary.html#k">K</a> | <a href="reference/glossary.html#m">M</a> | <a href="reference/glossary.html#n">N</a> | <a href="reference/glossary.html#o">O</a> | <a href="reference/glossary.html#p">P</a> | <a href="reference/glossary.html#r">R</a> | <a href="reference/glossary.html#s">S</a> | <a href="reference/glossary.html#t">T</a> | <a href="reference/glossary.html#w">W</a></p>
<h1 id="a"><a class="header" href="#a">A</a></h1>
<hr />
<h3 id="ad"><a class="header" href="#ad">AD</a></h3>
<p>Or <strong>Availability Domain</strong> </p>
<p>One or more isolated, fault-tolerant Oracle data centers that host cloud resources such as instances, volumes, and subnets. A region contains one or more availability domains.</p>
<h1 id="c"><a class="header" href="#c">C</a></h1>
<hr />
<h3 id="cni"><a class="header" href="#cni">CNI</a></h3>
<p>Or <strong>Container Network Interface</strong></p>
<p>A <a href="https://cncf.io">Cloud Native Computing Foundation</a> project that  consists of a specification and libraries for 
writing plugins to configure network interfaces in Linux containers, along with a number of supported plugins.</p>
<h1 id="f"><a class="header" href="#f">F</a></h1>
<hr />
<h3 id="fd"><a class="header" href="#fd">FD</a></h3>
<p>Or <strong>Fault Domain</strong> </p>
<p>A logical grouping of hardware and infrastructure within an <a href="reference/glossary.html#ad">availability domain</a>. Fault domains isolate resources during hardware failure or unexpected software changes.</p>
<h1 id="i"><a class="header" href="#i">I</a></h1>
<hr />
<h3 id="internet-gateway"><a class="header" href="#internet-gateway">Internet Gateway</a></h3>
<p>An Internet Gateway is an optional virtual router you can add to your <a href="reference/glossary.html#vcn">VCN</a> to enable direct connectivity to the Internet. It supports connections initiated from within the VCN (egress) and connections initiated from the Internet (ingress).</p>
<h1 id="n"><a class="header" href="#n">N</a></h1>
<hr />
<h3 id="nat-gateway"><a class="header" href="#nat-gateway">NAT Gateway</a></h3>
<p>A NAT Gateway gives cloud resources without public IP addresses access to the Internet without exposing those resources to incoming internet connections. A NAT Gateway can be added to a <a href="reference/glossary.html#vcn">VCN</a> to give instances in a private subnet access to the Internet.</p>
<h3 id="nsg"><a class="header" href="#nsg">NSG</a></h3>
<p>Or <strong>Network Security Group</strong></p>
<p>A <a href="https://docs.oracle.com/en-us/iaas/Content/Network/Concepts/networksecuritygroups.htm">Network security group (NSG)</a> acts as a virtual firewall for your compute instances and other kinds of resources. An NSG consists of a set of ingress and egress security rules that apply only to a set of VNICs of your choice in a single VCN (for example: all compute instances that act as web servers in the web tier of a multi-tier application in your VCN).</p>
<h1 id="r"><a class="header" href="#r">R</a></h1>
<hr />
<h3 id="region"><a class="header" href="#region">Region</a></h3>
<p>Oracle Cloud Infrastructure is hosted in regions and availability domains. A <a href="https://docs.oracle.com/en-us/iaas/Content/General/Concepts/regions.htm">region</a> is a localized geographic area, and an <a href="reference/glossary.html#ad">availability domain</a> is one or more data centers located within a region. A region is composed of one or more availability domains.</p>
<h1 id="s"><a class="header" href="#s">S</a></h1>
<hr />
<h3 id="service-gateway"><a class="header" href="#service-gateway">Service Gateway</a></h3>
<p>A service gateway lets your <a href="reference/glossary.html#vcn">VCN</a> privately access specific Oracle services without exposing the data to the public Internet. No <a href="reference/glossary.html#internet-gateway">Internet Gateway</a> or <a href="reference/glossary.html#nat-gateway">NAT</a> is required to reach those specific services. The resources in the VCN can be in a private subnet and use only private IP addresses. The traffic from the VCN to the Oracle service travels over the Oracle network fabric and never traverses the Internet.</p>
<h1 id="v"><a class="header" href="#v">V</a></h1>
<hr />
<h3 id="vcn"><a class="header" href="#vcn">VCN</a></h3>
<p>Or <strong>Virtual Cloud Network</strong></p>
<p>A <a href="https://docs.oracle.com/en-us/iaas/Content/Network/Tasks/managingVCNs_topic-Overview_of_VCNs_and_Subnets.htm#Overview">VCN</a> is a software-defined network that you set up in the Oracle Cloud Infrastructure data centers in a particular <a href="reference/glossary.html#region">region</a>.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
    </body>
</html>
